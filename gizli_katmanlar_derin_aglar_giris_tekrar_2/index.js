/*
ğŸ¯ Yeni Konu: Overfitting ile MÃ¼cadele â€” Dropout ve Regularization
Bu Ã¶rnekte, amacÄ±mÄ±z modelin aÅŸÄ±rÄ± Ã¶ÄŸrenmesini (overfitting) engellemek olacak. Modeli Ã§ok iyi eÄŸitirsek, eÄŸitim verisinde sÃ¼per sonuÃ§ alabilir ama yeni verilere karÅŸÄ± kÃ¶tÃ¼ sonuÃ§lar verir. Ä°ÅŸte bunu Ã¶nlemek iÃ§in:

ğŸ“˜ Konu BaÅŸlÄ±ÄŸÄ±:
Dropout ve L2 Regularization Kullanarak Overfitting'i Azaltma

ğŸ¯ GÃ¶rev:
Girdi: [yaÅŸ, gÃ¼nlÃ¼k kalori alÄ±mÄ±, egzersiz sÃ¼resi (dakika), uyku sÃ¼resi (saat)]

Ã‡Ä±ktÄ±: [vÃ¼cut yaÄŸÄ± yÃ¼zdesi]


ğŸ”§ YapÄ±lacaklar:
Normalizasyon (Ã¶nceki fonksiyonu kullanabilirsin)

Model:

dense(16, activation: 'relu', kernelRegularizer: l2)

dropout(0.3)

dense(8, activation: 'relu')

dense(1, activation: 'linear')

Optimizer: adam

Loss: meanSquaredError

Epoch: 600

EÄŸitim sonrasÄ± [25, 2500, 45, 7] girdisiyle vÃ¼cut yaÄŸÄ± tahmini al
 */

const tf = require("@tensorflow/tfjs-node")

const xsRaw = [
    [20, 2200, 30, 6],
    [25, 2500, 45, 7],
    [30, 2800, 60, 8],
    [35, 2000, 20, 5],
    [40, 1800, 15, 5],
    [28, 2700, 50, 7],
    [22, 2300, 35, 6],
    [38, 1900, 25, 6]
]

const ysRaw = [
    [18],
    [16],
    [15],
    [22],
    [25],
    [17],
    [19],
    [23]
]

// normalizasyon fonksiyonu oluÅŸturalÄ±m
function normalize(data){
    const dataT = tf.tensor2d(data)
    const min = dataT.min(0) // aixs boyunca min
    const max = dataT.max(0) // axis boyunca max
    const normalize = dataT.sub(min).div(max.sub(min))
    return {normalize,min,max}
}

// normalize uygulayalÄ±m
const {normalize : xsNorm,min : xsMin,max : xsMax} = normalize(xsRaw)
const {normalize : ysNorm,min : ysMin,max : ysMax} = normalize(ysRaw)

// model oluÅŸturalÄ±m
const model = tf.sequential()

// giriÅŸ katmanÄ±
model.add(tf.layers.dense({
    units : 16, // 16 nÃ¶ron,
    inputShape : [4], // 4 giriÅŸ
    activation : "relu", // karmaÅŸÄ±k veri analizi olacak. 0 larÄ± gÃ¶rmezden gel
    kernelRegularizer : "l1l2" // overfitting durumlarÄ±nda katman aÄŸÄ±rlÄ±klarÄ±na ceza katsayÄ±sÄ± uygula. AmaÃ§ modelin karmaÅŸÄ±k olmamasÄ±, genelleme yapabilmesi
}))

// gizli katman
model.add(tf.layers.dropout({
    rate : 0.3  // karmaÅŸÄ±k Ã¶ÄŸrenme olmasÄ±n diye nÃ¶ronlarÄ±n yÃ¼zde 30 unu kapattÄ±k
}))

// gizli katman
model.add(tf.layers.dense({
    units : 8, // 8 nÃ¶ron,
    activation : "relu", // karmaÅŸÄ±k veri analizi olacak. 0 larÄ± gÃ¶rmezden gel
}))

// Ã§Ä±kÄ±ÅŸ katmanÄ±
model.add(tf.layers.dense({
    units : 1, // 1 nÃ¶ron,
    activation : "linear", // direkt Ã§Ä±ktÄ±yÄ± basmak istedik
}))

// model derleyelim
model.compile({
    optimizer : "adam",
    loss : "meanSquaredError"
})

// model eÄŸitelim ve tahmin yaptÄ±ralÄ±m
async function trainAndPredict(){
    const fit_result = await model.fit(xsNorm,ysNorm,{
        epochs : 600
    })

    await model.save("file://./model")

    const loadedModel = await tf.loadLayersModel("file://./model/model.json")
    const inputRaw = tf.tensor2d([[24, 1300, 5, 9]])
    const inputNorm = inputRaw.sub(xsMin).div(xsMax.sub(xsMin))

    const predNorm = model.predict(inputNorm)
    const pred = predNorm.mul(ysMax.sub(ysMin)).add(ysMin)

    pred.print()

    console.log("Hata DeÄŸeri: ",fit_result.history.loss)

    const trust_value = await model.evaluate(xsNorm,ysNorm)

    console.log("DoÄŸruluk YÃ¼zdesi: ",trust_value.dataSync()[0])

    /*
    tahmini beklenen Ã§Ä±ktÄ±: 15.5 - 16.5 arasÄ±
     */
}
trainAndPredict()
